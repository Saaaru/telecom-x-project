# ü§ñ Instructivo: Machine Learning para Predicci√≥n de Churn - TelecomX

## üìã Introducci√≥n

Este instructivo te guiar√° paso a paso para desarrollar modelos predictivos de churn en TelecomX, bas√°ndote en el an√°lisis exploratorio ya completado en la Parte 1.

---

## üéØ Objetivos del Proyecto

- ‚úÖ Preparar los datos para modelado predictivo
- ‚úÖ Entrenar y evaluar m√∫ltiples modelos de clasificaci√≥n
- ‚úÖ Identificar los factores m√°s importantes para la predicci√≥n
- ‚úÖ Proporcionar recomendaciones estrat√©gicas basadas en datos

---

## üìÇ PASO 1: Preparaci√≥n del Entorno

### 1.1 Librer√≠as Necesarias

```python
# Manipulaci√≥n de datos
import pandas as pd
import numpy as np

# Visualizaci√≥n
import matplotlib.pyplot as plt
import seaborn as sns

# Preprocesamiento
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.preprocessing import OneHotEncoder
from pandas import get_dummies

# Modelos de Machine Learning
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC

# M√©tricas de evaluaci√≥n
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, classification_report
from sklearn.metrics import roc_auc_score, roc_curve

# Tratamiento de desbalance
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler

# Configuraci√≥n de visualizaci√≥n
plt.style.use('seaborn-v0_8')
sns.set_palette("husl")
```

### 1.2 Carga de Datos

```python
# Opci√≥n 1: Si tienes el CSV guardado de la Parte 1
df = pd.read_csv('telecom_data_limpio.csv')

# Opci√≥n 2: Si necesitas procesar desde el notebook original
# Ejecuta las celdas de extracci√≥n y transformaci√≥n del notebook
```

---

## üìä PASO 2: Preparaci√≥n de Datos para ML

### 2.1 Eliminaci√≥n de Columnas Irrelevantes

```python
# Eliminar ID del cliente (no aporta valor predictivo)
df_ml = df.drop(['customerID'], axis=1)

print(f"Dataset original: {df.shape}")
print(f"Dataset para ML: {df_ml.shape}")
print(f"Columnas eliminadas: customerID")
```

### 2.2 An√°lisis de Balance de Clases

```python
# Verificar distribuci√≥n de la variable objetivo
churn_distribution = df_ml['Churn'].value_counts()
churn_percentage = df_ml['Churn'].value_counts(normalize=True) * 100

print("=== DISTRIBUCI√ìN DE CHURN ===")
print(f"No Churn: {churn_distribution['No']} ({churn_percentage['No']:.1f}%)")
print(f"Churn: {churn_distribution['Yes']} ({churn_percentage['Yes']:.1f}%)")

# Visualizaci√≥n
plt.figure(figsize=(8, 6))
sns.countplot(data=df_ml, x='Churn', palette=['lightgreen', 'lightcoral'])
plt.title('Distribuci√≥n de Clases - Churn')
for i, v in enumerate(churn_distribution):
    plt.text(i, v + 50, f'{churn_percentage.iloc[i]:.1f}%', 
             ha='center', va='bottom', fontsize=12, fontweight='bold')
plt.show()

# Evaluar si hay desbalance significativo
imbalance_ratio = churn_distribution['No'] / churn_distribution['Yes']
print(f"\nRatio de desbalance: {imbalance_ratio:.2f}:1")

if imbalance_ratio > 3:
    print("‚ö†Ô∏è  DESBALANCE DETECTADO - Considerar t√©cnicas de balanceo")
else:
    print("‚úÖ Balance de clases aceptable")
```

### 2.3 Codificaci√≥n de Variables Categ√≥ricas

```python
# Identificar variables categ√≥ricas
categorical_columns = df_ml.select_dtypes(include=['object']).columns.tolist()
categorical_columns.remove('Churn')  # Excluir variable objetivo

print("Variables categ√≥ricas a codificar:", categorical_columns)

# M√©todo 1: One-Hot Encoding con pandas
df_encoded = pd.get_dummies(df_ml, columns=categorical_columns, drop_first=True)

print(f"Dimensiones despu√©s de encoding: {df_encoded.shape}")
print(f"Nuevas variables creadas: {df_encoded.shape[1] - df_ml.shape[1]}")

# Convertir variable objetivo a num√©rica
df_encoded['Churn'] = df_encoded['Churn'].map({'No': 0, 'Yes': 1})

# Verificar el resultado
print("\nPrimeras columnas del dataset codificado:")
print(df_encoded.columns.tolist()[:10])
```

### 2.4 An√°lisis de Correlaci√≥n Avanzado

```python
# Calcular matriz de correlaci√≥n
correlation_matrix = df_encoded.corr()

# Correlaciones con la variable objetivo
churn_correlations = correlation_matrix['Churn'].sort_values(key=abs, ascending=False)

print("=== TOP 10 VARIABLES M√ÅS CORRELACIONADAS CON CHURN ===")
for i, (var, corr) in enumerate(churn_correlations.head(11).items()):
    if var != 'Churn':  # Excluir la correlaci√≥n consigo misma
        print(f"{i}: {var:<30} | Correlaci√≥n: {corr:>6.3f}")

# Visualizaci√≥n de correlaciones importantes
plt.figure(figsize=(12, 8))
top_corr = churn_correlations.drop('Churn').head(15)
sns.barplot(x=top_corr.values, y=top_corr.index, palette='RdYlBu_r')
plt.title('Top 15 Variables m√°s Correlacionadas con Churn')
plt.xlabel('Correlaci√≥n con Churn')
plt.axvline(x=0, color='black', linestyle='--', alpha=0.7)
plt.tight_layout()
plt.show()
```

---

## üîß PASO 3: Divisi√≥n de Datos y Normalizaci√≥n

### 3.1 Separaci√≥n de Variables

```python
# Separar caracter√≠sticas (X) y variable objetivo (y)
X = df_encoded.drop('Churn', axis=1)
y = df_encoded['Churn']

print(f"Caracter√≠sticas (X): {X.shape}")
print(f"Variable objetivo (y): {y.shape}")
print(f"Distribuci√≥n de y: {y.value_counts().to_dict()}")
```

### 3.2 Divisi√≥n Train/Test

```python
# Divisi√≥n estratificada para mantener proporci√≥n de clases
X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.3,  # 70% entrenamiento, 30% prueba
    random_state=42,
    stratify=y  # Mantener proporci√≥n de clases
)

print("=== DIVISI√ìN DE DATOS ===")
print(f"Entrenamiento: {X_train.shape[0]} muestras")
print(f"Prueba: {X_test.shape[0]} muestras")
print(f"Distribuci√≥n Churn en entrenamiento: {y_train.value_counts().to_dict()}")
print(f"Distribuci√≥n Churn en prueba: {y_test.value_counts().to_dict()}")
```

### 3.3 Normalizaci√≥n de Datos

```python
# Identificar variables num√©ricas que necesitan normalizaci√≥n
numeric_features = X_train.select_dtypes(include=[np.number]).columns.tolist()
print(f"Variables num√©ricas a normalizar: {numeric_features}")

# Crear el escalador
scaler = StandardScaler()

# Ajustar el escalador solo con datos de entrenamiento
X_train_scaled = X_train.copy()
X_test_scaled = X_test.copy()

X_train_scaled[numeric_features] = scaler.fit_transform(X_train[numeric_features])
X_test_scaled[numeric_features] = scaler.transform(X_test[numeric_features])

print("‚úÖ Normalizaci√≥n completada")

# Verificar normalizaci√≥n
print("\nEstad√≠sticas despu√©s de normalizaci√≥n (variables num√©ricas):")
print(X_train_scaled[numeric_features].describe().round(3))
```

---

## ü§ñ PASO 4: Entrenamiento de Modelos

### 4.1 Configuraci√≥n de Modelos

```python
# Diccionario de modelos a entrenar
models = {
    'Logistic_Regression': LogisticRegression(random_state=42, max_iter=1000),
    'Random_Forest': RandomForestClassifier(random_state=42, n_estimators=100),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Decision_Tree': DecisionTreeClassifier(random_state=42, max_depth=10),
    'SVM': SVC(random_state=42, probability=True)
}

# Diccionario para almacenar resultados
results = {}
trained_models = {}
```

### 4.2 Entrenamiento y Evaluaci√≥n

```python
def evaluate_model(name, model, X_train, X_test, y_train, y_test):
    """
    Entrena un modelo y calcula m√©tricas de evaluaci√≥n
    """
    print(f"\nüîÑ Entrenando {name}...")
    
    # Entrenar modelo
    model.fit(X_train, y_train)
    
    # Predicciones
    y_train_pred = model.predict(X_train)
    y_test_pred = model.predict(X_test)
    
    # Probabilidades (para ROC-AUC)
    try:
        y_test_proba = model.predict_proba(X_test)[:, 1]
    except:
        y_test_proba = y_test_pred  # Para modelos sin predict_proba
    
    # M√©tricas
    metrics = {
        'train_accuracy': accuracy_score(y_train, y_train_pred),
        'test_accuracy': accuracy_score(y_test, y_test_pred),
        'precision': precision_score(y_test, y_test_pred),
        'recall': recall_score(y_test, y_test_pred),
        'f1_score': f1_score(y_test, y_test_pred),
        'roc_auc': roc_auc_score(y_test, y_test_proba) if len(np.unique(y_test_proba)) > 1 else 0
    }
    
    # Calcular overfitting
    metrics['overfitting'] = metrics['train_accuracy'] - metrics['test_accuracy']
    
    print(f"‚úÖ {name} entrenado")
    print(f"   Accuracy Test: {metrics['test_accuracy']:.3f}")
    print(f"   F1-Score: {metrics['f1_score']:.3f}")
    print(f"   Overfitting: {metrics['overfitting']:.3f}")
    
    return metrics, model

# Entrenar modelos con datos normalizados
print("=== ENTRENAMIENTO CON DATOS NORMALIZADOS ===")
for name, model in models.items():
    if name in ['Logistic_Regression', 'KNN', 'SVM']:  # Modelos que necesitan normalizaci√≥n
        metrics, trained_model = evaluate_model(name, model, X_train_scaled, X_test_scaled, y_train, y_test)
    else:  # Modelos basados en √°rboles
        metrics, trained_model = evaluate_model(name, model, X_train, X_test, y_train, y_test)
    
    results[name] = metrics
    trained_models[name] = trained_model
```

---

## üìä PASO 5: Evaluaci√≥n y Comparaci√≥n de Modelos

### 5.1 Tabla Comparativa

```python
# Crear DataFrame con resultados
results_df = pd.DataFrame(results).T
results_df = results_df.round(3)

print("=== COMPARACI√ìN DE MODELOS ===")
print(results_df.to_string())

# Identificar mejor modelo
best_model_name = results_df['test_accuracy'].idxmax()
best_f1_model = results_df['f1_score'].idxmax()

print(f"\nüèÜ Mejor modelo por Accuracy: {best_model_name} ({results_df.loc[best_model_name, 'test_accuracy']:.3f})")
print(f"üéØ Mejor modelo por F1-Score: {best_f1_model} ({results_df.loc[best_f1_model, 'f1_score']:.3f})")
```

### 5.2 Visualizaci√≥n de Resultados

```python
# Gr√°fico comparativo de m√©tricas
fig, axes = plt.subplots(2, 2, figsize=(15, 10))
fig.suptitle('Comparaci√≥n de Rendimiento de Modelos', fontsize=16)

# Accuracy
axes[0,0].bar(results_df.index, results_df['test_accuracy'], color='skyblue')
axes[0,0].set_title('Accuracy')
axes[0,0].set_ylabel('Score')
axes[0,0].tick_params(axis='x', rotation=45)

# F1-Score
axes[0,1].bar(results_df.index, results_df['f1_score'], color='lightgreen')
axes[0,1].set_title('F1-Score')
axes[0,1].set_ylabel('Score')
axes[0,1].tick_params(axis='x', rotation=45)

# Precision vs Recall
axes[1,0].scatter(results_df['precision'], results_df['recall'], s=100, alpha=0.7)
for i, model in enumerate(results_df.index):
    axes[1,0].annotate(model, (results_df.iloc[i]['precision'], results_df.iloc[i]['recall']))
axes[1,0].set_xlabel('Precision')
axes[1,0].set_ylabel('Recall')
axes[1,0].set_title('Precision vs Recall')

# Overfitting
colors = ['red' if x > 0.05 else 'green' for x in results_df['overfitting']]
axes[1,1].bar(results_df.index, results_df['overfitting'], color=colors, alpha=0.7)
axes[1,1].set_title('Overfitting (Train Acc - Test Acc)')
axes[1,1].set_ylabel('Diferencia')
axes[1,1].tick_params(axis='x', rotation=45)
axes[1,1].axhline(y=0.05, color='red', linestyle='--', alpha=0.5, label='Umbral Overfitting')

plt.tight_layout()
plt.show()
```

### 5.3 Matriz de Confusi√≥n del Mejor Modelo

```python
# Seleccionar el mejor modelo
best_model = trained_models[best_f1_model]

# Hacer predicciones
if best_f1_model in ['Logistic_Regression', 'KNN', 'SVM']:
    y_pred = best_model.predict(X_test_scaled)
else:
    y_pred = best_model.predict(X_test)

# Matriz de confusi√≥n
cm = confusion_matrix(y_test, y_pred)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=['No Churn', 'Churn'], 
            yticklabels=['No Churn', 'Churn'])
plt.title(f'Matriz de Confusi√≥n - {best_f1_model}')
plt.ylabel('Valores Reales')
plt.xlabel('Predicciones')
plt.show()

# Reporte de clasificaci√≥n
print(f"\n=== REPORTE DETALLADO - {best_f1_model} ===")
print(classification_report(y_test, y_pred, target_names=['No Churn', 'Churn']))
```

---

## üîç PASO 6: An√°lisis de Importancia de Variables

### 6.1 Feature Importance (Random Forest)

```python
if 'Random_Forest' in trained_models:
    rf_model = trained_models['Random_Forest']
    feature_importance = pd.DataFrame({
        'feature': X_train.columns,
        'importance': rf_model.feature_importances_
    }).sort_values('importance', ascending=False)
    
    plt.figure(figsize=(12, 8))
    sns.barplot(data=feature_importance.head(15), y='feature', x='importance', palette='viridis')
    plt.title('Top 15 Variables m√°s Importantes (Random Forest)')
    plt.xlabel('Importancia')
    plt.tight_layout()
    plt.show()
    
    print("=== TOP 10 VARIABLES M√ÅS IMPORTANTES ===")
    for i, row in feature_importance.head(10).iterrows():
        print(f"{row.name+1:2d}. {row['feature']:<30} | Importancia: {row['importance']:.3f}")
```

### 6.2 Coeficientes (Regresi√≥n Log√≠stica)

```python
if 'Logistic_Regression' in trained_models:
    lr_model = trained_models['Logistic_Regression']
    coefficients = pd.DataFrame({
        'feature': X_train.columns,
        'coefficient': lr_model.coef_[0]
    })
    coefficients['abs_coefficient'] = abs(coefficients['coefficient'])
    coefficients = coefficients.sort_values('abs_coefficient', ascending=False)
    
    plt.figure(figsize=(12, 8))
    top_coef = coefficients.head(15)
    colors = ['red' if x < 0 else 'blue' for x in top_coef['coefficient']]
    sns.barplot(data=top_coef, y='feature', x='coefficient', palette=colors)
    plt.title('Top 15 Coeficientes m√°s Influyentes (Regresi√≥n Log√≠stica)')
    plt.xlabel('Coeficiente (+ aumenta Churn, - disminuye Churn)')
    plt.axvline(x=0, color='black', linestyle='--', alpha=0.5)
    plt.tight_layout()
    plt.show()
    
    print("=== TOP 10 COEFICIENTES M√ÅS INFLUYENTES ===")
    for i, row in coefficients.head(10).iterrows():
        direction = "üî¥ Aumenta" if row['coefficient'] > 0 else "üü¢ Disminuye"
        print(f"{i+1:2d}. {row['feature']:<30} | {direction} Churn: {row['coefficient']:>6.3f}")
```

---

## üìã PASO 7: Tratamiento de Desbalance (Opcional)

### 7.1 Aplicar SMOTE

```python
# Solo si detectamos desbalance significativo
if imbalance_ratio > 3:
    print("=== APLICANDO SMOTE PARA BALANCEAR CLASES ===")
    
    # Aplicar SMOTE
    smote = SMOTE(random_state=42)
    X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)
    
    print(f"Antes de SMOTE: {y_train.value_counts().to_dict()}")
    print(f"Despu√©s de SMOTE: {pd.Series(y_train_balanced).value_counts().to_dict()}")
    
    # Re-entrenar mejor modelo con datos balanceados
    best_model_balanced = type(trained_models[best_f1_model])(random_state=42)
    best_model_balanced.fit(X_train_balanced, y_train_balanced)
    
    # Evaluar modelo balanceado
    if best_f1_model in ['Logistic_Regression', 'KNN', 'SVM']:
        y_pred_balanced = best_model_balanced.predict(X_test_scaled)
    else:
        y_pred_balanced = best_model_balanced.predict(X_test)
    
    print(f"\n=== COMPARACI√ìN CON/SIN BALANCEO ===")
    print(f"F1-Score Original: {f1_score(y_test, y_pred):.3f}")
    print(f"F1-Score Balanceado: {f1_score(y_test, y_pred_balanced):.3f}")
    print(f"Recall Original: {recall_score(y_test, y_pred):.3f}")
    print(f"Recall Balanceado: {recall_score(y_test, y_pred_balanced):.3f}")
```

---

## üìä PASO 8: Insights y Recomendaciones Estrat√©gicas

### 8.1 An√°lisis de Factores Clave

```python
print("="*60)
print("üéØ FACTORES CLAVE QUE INFLUYEN EN LA CANCELACI√ìN")
print("="*60)

# Basado en el an√°lisis anterior, identifica los factores m√°s importantes
key_factors = [
    "Contract_Month-to-month",  # Contratos mensuales
    "tenure",                   # Antig√ºedad baja
    "Charges.Monthly",          # Cargos mensuales altos
    "InternetService_Fiber optic",  # Servicio de fibra √≥ptica
    "PaymentMethod_Electronic check"  # M√©todo de pago
]

print("\nüìà TOP FACTORES DE RIESGO:")
for i, factor in enumerate(key_factors, 1):
    if factor in feature_importance['feature'].values:
        importance = feature_importance[feature_importance['feature'] == factor]['importance'].iloc[0]
        print(f"{i}. {factor:<35} | Importancia: {importance:.3f}")

# Recomendaciones estrat√©gicas
print("\n" + "="*60)
print("üí° RECOMENDACIONES ESTRAT√âGICAS")
print("="*60)

recommendations = [
    "üéØ RETENCI√ìN TEMPRANA: Implementar programa de seguimiento intensivo para clientes nuevos (primeros 6 meses)",
    "üìã CONTRATOS ANUALES: Incentivar migraci√≥n de contratos mes-a-mes a anuales con descuentos atractivos",
    "üí∞ REVISI√ìN DE PRECIOS: Analizar estructura de precios de fibra √≥ptica vs satisfacci√≥n del cliente",
    "üîß CALIDAD DE SERVICIO: Mejorar estabilidad y soporte t√©cnico para servicios de fibra √≥ptica",
    "üí≥ M√âTODOS DE PAGO: Promocionar m√©todos de pago m√°s estables (d√©bito autom√°tico vs cheque electr√≥nico)",
    "üéÅ PROGRAMAS DE LEALTAD: Crear incentivos progresivos basados en antig√ºedad del cliente",
    "üìû INTERVENCI√ìN PROACTIVA: Identificar clientes en riesgo usando el modelo predictivo para intervenci√≥n temprana"
]

for rec in recommendations:
    print(f"\n{rec}")

print(f"\n{'='*60}")
print(f"üìä MODELO RECOMENDADO: {best_f1_model}")
print(f"üéØ F1-Score: {results_df.loc[best_f1_model, 'f1_score']:.3f}")
print(f"üéØ Accuracy: {results_df.loc[best_f1_model, 'test_accuracy']:.3f}")
print(f"üìà ROC-AUC: {results_df.loc[best_f1_model, 'roc_auc']:.3f}")
print("="*60)
```

---

## üíæ PASO 9: Guardar Resultados

```python
# Guardar el mejor modelo
import joblib

# Guardar modelo y escalador
joblib.dump(trained_models[best_f1_model], f'best_model_{best_f1_model}.pkl')
joblib.dump(scaler, 'scaler.pkl')

# Guardar resultados
results_df.to_csv('model_comparison_results.csv')
feature_importance.to_csv('feature_importance.csv', index=False)

# Guardar dataset procesado
df_encoded.to_csv('telecom_data_processed_for_ml.csv', index=False)

print("‚úÖ Modelos y resultados guardados exitosamente:")
print(f"   - best_model_{best_f1_model}.pkl")
print(f"   - scaler.pkl")
print(f"   - model_comparison_results.csv")
print(f"   - feature_importance.csv")
print(f"   - telecom_data_processed_for_ml.csv")
```

---

## üéØ Resumen del Pipeline Completo

### ‚úÖ Checklist de Completion

- [ ] **Preparaci√≥n de datos**: Eliminaci√≥n de columnas irrelevantes
- [ ] **Codificaci√≥n categ√≥rica**: One-hot encoding aplicado
- [ ] **An√°lisis de balance**: Evaluaci√≥n de desbalance de clases
- [ ] **Divisi√≥n de datos**: Train/test split estratificado
- [ ] **Normalizaci√≥n**: StandardScaler para modelos apropiados
- [ ] **Entrenamiento**: 5 modelos diferentes entrenados
- [ ] **Evaluaci√≥n**: M√©tricas completas calculadas
- [ ] **Comparaci√≥n**: Identificaci√≥n del mejor modelo
- [ ] **An√°lisis de importancia**: Variables m√°s influyentes identificadas
- [ ] **Recomendaciones**: Estrategias basadas en insights
- [ ] **Guardado**: Modelos y resultados preservados

### üìä M√©tricas Clave a Reportar

1. **Accuracy**: Precisi√≥n general del modelo
2. **Precision**: De los predichos como churn, cu√°ntos realmente lo son
3. **Recall**: De los que realmente cancelan, cu√°ntos detectamos
4. **F1-Score**: Balance entre precision y recall
5. **ROC-AUC**: Capacidad de discriminaci√≥n del modelo
6. **Feature Importance**: Variables m√°s predictivas

### üéØ Entregables Finales

1. **Notebook completo** con todo el pipeline
2. **Modelo entrenado** (.pkl file)
3. **Reporte de m√©tricas** comparativas
4. **Lista de variables importantes** con interpretaci√≥n
5. **Recomendaciones estrat√©gicas** basadas en resultados

---

¬°Con este instructivo tendr√°s una gu√≠a completa para desarrollar un pipeline robusto de Machine Learning para la predicci√≥n de churn en TelecomX! üöÄ